{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOSS AND ACCURACY PLOT\n",
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    fig.savefig('plot.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.legacy.preprocessing.image.ImageDataGenerator object at 0x00000212050BEF30>\n",
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#Data gfenerators\n",
    "\n",
    "\n",
    "train_dir = 'C:/Users/athen/OneDrive/Documents/Mini project 2/archive (1)/images/images/train'\n",
    "val_dir = 'C:/Users/athen/OneDrive/Documents/Mini project 2/archive (1)/images/images/test'\n",
    "\n",
    "num_train = 28709\n",
    "num_val = 7178\n",
    "batch_size = 64\n",
    "num_epoch = 2\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "print(datagen)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 GET https://storage.googleapis.com/download/storage/v1/b/mini-project-d9780.appspot.com/o/videos%2Fvideo.mp4?alt=media: No such object: mini-project-d9780.appspot.com/videos/video.mp4: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidResponse\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:4362\u001b[0m, in \u001b[0;36mBlob._prep_and_do_download\u001b[1;34m(self, file_obj, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[0;32m   4361\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4362\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4373\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4374\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mInvalidResponse \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:1017\u001b[0m, in \u001b[0;36mBlob._do_download\u001b[1;34m(self, transport, file_obj, download_url, headers, start, end, raw_download, timeout, checksum, retry)\u001b[0m\n\u001b[0;32m   1016\u001b[0m download\u001b[38;5;241m.\u001b[39m_retry_strategy \u001b[38;5;241m=\u001b[39m retry_strategy\n\u001b[1;32m-> 1017\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mdownload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_headers_from_download(response)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\resumable_media\\requests\\download.py:237\u001b[0m, in \u001b[0;36mDownload.consume\u001b[1;34m(self, transport, timeout)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_and_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriable_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_strategy\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\resumable_media\\requests\\_request_helpers.py:155\u001b[0m, in \u001b[0;36mwait_and_retry\u001b[1;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _CONNECTION_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\resumable_media\\requests\\download.py:219\u001b[0m, in \u001b[0;36mDownload.consume.<locals>.retriable_request\u001b[1;34m()\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object_generation \u001b[38;5;241m=\u001b[39m _helpers\u001b[38;5;241m.\u001b[39m_parse_generation_header(\n\u001b[0;32m    216\u001b[0m         result, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_headers\n\u001b[0;32m    217\u001b[0m     )\n\u001b[1;32m--> 219\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# With decompressive transcoding, GCS serves back the whole file regardless of the range request,\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# thus we reset the stream position to the start of the stream.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# See: https://cloud.google.com/storage/docs/transcoding#range\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\resumable_media\\_download.py:188\u001b[0m, in \u001b[0;36mDownload._process_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m \u001b[43m_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_status_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ACCEPTABLE_STATUS_CODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\resumable_media\\_helpers.py:108\u001b[0m, in \u001b[0;36mrequire_status_code\u001b[1;34m(response, status_codes, get_status_code, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m         callback()\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m common\u001b[38;5;241m.\u001b[39mInvalidResponse(\n\u001b[0;32m    109\u001b[0m         response,\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest failed with status code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    111\u001b[0m         status_code,\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected one of\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;241m*\u001b[39mstatus_codes\n\u001b[0;32m    114\u001b[0m     )\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status_code\n",
      "\u001b[1;31mInvalidResponse\u001b[0m: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideos/video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your Firebase Storage path\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Stream video from Firebase Storage\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m video_stream \u001b[38;5;241m=\u001b[39m \u001b[43mstream_video_from_firebase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Analyze video frames\u001b[39;00m\n\u001b[0;32m     61\u001b[0m result \u001b[38;5;241m=\u001b[39m analyze_video(video_stream, model)\n",
      "Cell \u001b[1;32mIn[21], line 19\u001b[0m, in \u001b[0;36mstream_video_from_firebase\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream_video_from_firebase\u001b[39m(file_path):\n\u001b[0;32m     18\u001b[0m     blob \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mblob(file_path)\n\u001b[1;32m---> 19\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mblob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_as_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:1435\u001b[0m, in \u001b[0;36mBlob.download_as_bytes\u001b[1;34m(self, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download the contents of this blob as a bytes object.\u001b[39;00m\n\u001b[0;32m   1346\u001b[0m \n\u001b[0;32m   1347\u001b[0m \u001b[38;5;124;03mIf :attr:`user_project` is set on the bucket, bills the API request\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;124;03m:raises: :class:`google.cloud.exceptions.NotFound`\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1433\u001b[0m string_buffer \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[1;32m-> 1435\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prep_and_do_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_etag_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_etag_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_etag_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_etag_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_generation_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_generation_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_generation_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_generation_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_metageneration_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_metageneration_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m string_buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:4375\u001b[0m, in \u001b[0;36mBlob._prep_and_do_download\u001b[1;34m(self, file_obj, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[0;32m   4362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_download(\n\u001b[0;32m   4363\u001b[0m         transport,\n\u001b[0;32m   4364\u001b[0m         file_obj,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4372\u001b[0m         retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m   4373\u001b[0m     )\n\u001b[0;32m   4374\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mInvalidResponse \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m-> 4375\u001b[0m     \u001b[43m_raise_from_invalid_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:4847\u001b[0m, in \u001b[0;36m_raise_from_invalid_response\u001b[1;34m(error)\u001b[0m\n\u001b[0;32m   4843\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(error)\n\u001b[0;32m   4845\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 4847\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_status(response\u001b[38;5;241m.\u001b[39mstatus_code, message, response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "\u001b[1;31mNotFound\u001b[0m: 404 GET https://storage.googleapis.com/download/storage/v1/b/mini-project-d9780.appspot.com/o/videos%2Fvideo.mp4?alt=media: No such object: mini-project-d9780.appspot.com/videos/video.mp4: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, storage\n",
    "\n",
    "service_account_key = 'C:/Users/athen/OneDrive/Documents/Mini project 2/mini-project-d9780-firebase-adminsdk-excc6-1f7073b6d8.json'\n",
    "\n",
    "# Check if Firebase app is already initialized\n",
    "try:\n",
    "    firebase_admin.get_app()\n",
    "except ValueError:\n",
    "    # Initialize Firebase app with credentials and storage bucket\n",
    "    cred = credentials.Certificate(service_account_key)\n",
    "    firebase_admin.initialize_app(cred, {'storageBucket': 'mini-project-d9780.appspot.com'})\n",
    "bucket = storage.bucket()\n",
    "\n",
    "def stream_video_from_firebase(file_path):\n",
    "    blob = bucket.blob(file_path)\n",
    "    stream = blob.download_as_bytes()\n",
    "    return stream\n",
    "\n",
    "class EmotionDetector:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    \n",
    "    def predict(self, frame):\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "        frame = cv2.resize(frame, (48, 48))   \n",
    "        frame = frame / 255.0 \n",
    "        frame = frame.reshape(1, 48, 48, 1) \n",
    "\n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(frame)\n",
    "        return predictions\n",
    "\n",
    "    def detect_emotions(self,frame):\n",
    "        predictions = self.predict(frame)\n",
    "        \n",
    "        # Convert predictions to emotion labels\n",
    "        # This is a dummy implementation, replace with your actual logic\n",
    "        emotions = [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "        detected_emotions = [emotions[pred.argmax()] for pred in predictions]\n",
    "\n",
    "        return detected_emotions \n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "if __name__ == '__main__':\n",
    "    # Load your pre-trained Keras model\n",
    "    model_path = 'emotion_detection_model.h5'\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Define the path to the video in Firebase Storage\n",
    "    video_path = 'videos/video.mp4'  # Replace with your Firebase Storage path\n",
    "    \n",
    "    # Stream video from Firebase Storage\n",
    "    video_stream = stream_video_from_firebase(video_path)\n",
    "    \n",
    "    # Analyze video frames\n",
    "    result = analyze_video(video_stream, model)\n",
    "    \n",
    "    # Close the video stream when done\n",
    "    video_stream.close()\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_blob):\n",
    "        self.path =video_blob\n",
    "        self.capture = cv2.VideoCapture(video_blob)\n",
    "        if not self.capture.isOpened():\n",
    "            print(\"Error: Could not open video.\")\n",
    "\n",
    "    \n",
    "    def analyze(self, detector, display=False, save_path=\"frames\"):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        frame_count = 0\n",
    "        results = []\n",
    "        while True:\n",
    "            ret, frame = self.capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "    \n",
    "            # Perform emotion detection on the frame\n",
    "            result = detector.detect_emotions(frame) \n",
    "            results.append((frame_count, result))\n",
    "            print(f\"Frame {frame_count}: {result}\")# Fixing the method call\n",
    "    \n",
    "            if display:\n",
    "                for emotion in result:\n",
    "                    cv2.putText(frame, str(emotion), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                frame_filename = os.path.join(save_path, f\"frame_{frame_count:04d}.jpg\")\n",
    "                cv2.imwrite(frame_filename, frame)\n",
    "                frame_count += 1\n",
    "\n",
    "        self.capture.release()\n",
    "        print(\"Analysis complete.\") \n",
    "        return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.save('emotion_detection_model.h5')\n",
    "model = keras.models.load_model(\"emotion_detection_model.h5\")\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train // batch_size,\n",
    "    epochs=num_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_val // batch_size)\n",
    "\n",
    "video = Video(path_to_video)\n",
    "emotion_detector = EmotionDetector(model)\n",
    "results = video.analyze(emotion_detector, display=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresults\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: analyze method returned None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Convert results to pandas DataFrame\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "if results is None:\n",
    "    print(\"Error: analyze method returned None\")\n",
    "else:\n",
    "    # Convert results to pandas DataFrame\n",
    "   data = {\"frame_count\": [], \"happy\": [], \"surprise\": [], \n",
    "        \"angry\": [], \"disgust\": [], \"fear\": [], \"sad\": []}\n",
    "\n",
    "# Populate the DataFrame with results\n",
    "for frame_count, emotions in results:\n",
    "    data[\"frame_count\"].append(frame_count)\n",
    "    data[\"happy\"].append(emotions.count(\"happy\"))\n",
    "    data[\"surprise\"].append(emotions.count(\"surprise\"))\n",
    "    data[\"angry\"].append(emotions.count(\"angry\"))\n",
    "    data[\"disgust\"].append(emotions.count(\"disgust\"))\n",
    "    data[\"fear\"].append(emotions.count(\"fear\"))\n",
    "    data[\"sad\"].append(emotions.count(\"sad\"))\n",
    "    emotions_df = pd.DataFrame(data)\n",
    "\n",
    "    # Display the first few rows of the DataFrame\n",
    "    print(emotions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person is not interested\n"
     ]
    }
   ],
   "source": [
    "# Predict whether a person show interest in a topic or not\n",
    "\n",
    "positive_emotions = sum(emotions_df.happy) + sum(emotions_df.surprise)\n",
    "negative_emotions = sum(emotions_df.angry) + sum(emotions_df.disgust) + sum(emotions_df.fear) + sum(emotions_df.sad)\n",
    "\n",
    "if positive_emotions > negative_emotions:\n",
    "    print(\"Person is interested\")\n",
    "    update_result(\"Person is satisfied\")\n",
    "elif positive_emotions < negative_emotions:\n",
    "    print(\"Person is not interested\")\n",
    "    update_result(\"Person is not satisfied\")\n",
    "else:\n",
    "    print(\"Person is neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to neon\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'host' : 'ep-wild-scene-a1bnv5tq.ap-southeast-1.aws.neon.tech',\n",
    "    'database' : 'miniproject',\n",
    "    'user' : 'athena',\n",
    "    'password' : '0hStGLnb5fDa',\n",
    "    'port': '5432'\n",
    "}\n",
    "engine = create_engine(f'postgresql://{db_params['user']}:{db_params['password']}@{db_params['port']}/{db_params['database']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=db_params['ep-wild-scene-a1bnv5tq.ap-southeast-1.aws.neon.tech'],\n",
    "    database=db_params['miniproject'],\n",
    "    user=db_params['athena'],\n",
    "    password=db_params['0hStGLnb5fDa'],\n",
    "    port=db_params['5432']\n",
    "\n",
    "cursor = conn.cursor()\n",
    "def update_result(result):\n",
    "    cursor.execute('UPDATE uploaded_videos VALUES ()', (result,))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    success,frame=camera.read()\n",
    "    if success:\n",
    "        img=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "        cv2.imshow(\"output\",frame)\n",
    "        k=cv2.waitKey(1)\n",
    "        if k==ord(\"a\"):\n",
    "            camera.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
